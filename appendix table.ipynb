{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# For the actual KIID Setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random, copy, os\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import time\n",
    "from scipy.optimize import linprog\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run wrapper_classes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run algorithm_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Set up the experiment\n",
    "## 0.1 Read in cleaned up, processed dataframe of drivers and requests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "filtered_df = pd.read_csv('filtered data/filtered_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def run_experiment(num_U,num_V,driver_quotas,rider_tolerances, alphas, betas, gammas, num_loops, verbose = False):\n",
    "    driver_entries = []\n",
    "\n",
    "    #1. First read in the drivers and riders as objects\n",
    "    hack_licenses = filtered_df['hack_license'].unique()\n",
    "\n",
    "    print(len(hack_licenses))\n",
    "    print(len(filtered_df))\n",
    "    chosen_licenses = np.random.choice(hack_licenses,size = num_U)\n",
    "\n",
    "    for i in range(chosen_licenses.shape[0]):\n",
    "        entries = filtered_df.loc[filtered_df['hack_license'] == chosen_licenses[i]]\n",
    "        driver_entries.append(entries.sample(n = 1))\n",
    "\n",
    "    driver_entries = pd.concat(driver_entries)\n",
    "    rider_entries = filtered_df.sample(n = num_V)\n",
    "\n",
    "    drivers = []\n",
    "    requests = []\n",
    "\n",
    "    d_id = 0\n",
    "    for index, row in driver_entries.iterrows():\n",
    "        init_lat_bin = row['init_lat_bin']\n",
    "        init_long_bin = row['init_long_bin']\n",
    "\n",
    "        pickup_lat_bin = row['pickup_lat_bin']\n",
    "        pickup_long_bin = row['pickup_long_bin']\n",
    "\n",
    "        dropoff_lat_bin = row['dropoff_lat_bin']\n",
    "        dropoff_long_bin = row['dropoff_long_bin']\n",
    "\n",
    "        driver_race = row['driver_race']\n",
    "        driver_gender = row['driver_gender']\n",
    "\n",
    "        drivers.append(Driver(d_id = d_id, driver_race = driver_race, driver_gender = driver_gender, pickup_lat_bin = pickup_lat_bin,\\\n",
    "                              pickup_long_bin = pickup_long_bin, driver_init_lat = init_lat_bin, driver_init_long = init_long_bin,\\\n",
    "                              quota = random.choice(driver_quotas), capacity = driver_capacity))\n",
    "        d_id += 1\n",
    "\n",
    "    r_id = 0\n",
    "    for index, row in rider_entries.iterrows():\n",
    "        pickup_lat_bin = row['pickup_lat_bin']\n",
    "        pickup_long_bin = row['pickup_long_bin']\n",
    "\n",
    "        dropoff_lat_bin = row['dropoff_lat_bin']\n",
    "        dropoff_long_bin = row['dropoff_long_bin']\n",
    "\n",
    "        driver_race = row['driver_race']\n",
    "        driver_gender = row['driver_gender']\n",
    "\n",
    "        pickup_latitude = row['pickup_latitude']\n",
    "        pickup_longitude = row['pickup_longitude']\n",
    "\n",
    "        dropoff_latitude = row['dropoff_latitude']\n",
    "        dropoff_longitude = row['dropoff_longitude']\n",
    "\n",
    "        request_gender = row['requests_gender']\n",
    "        request_race = row['requests_race']\n",
    "\n",
    "        requests.append(Request(pickup_lat_bin = pickup_lat_bin, pickup_long_bin = pickup_long_bin, dropoff_lat_bin = dropoff_lat_bin,\\\n",
    "                                dropoff_long_bin = dropoff_long_bin, pickup_latitude = pickup_latitude, pickup_longitude = pickup_longitude,\\\n",
    "                                dropoff_latitude = dropoff_latitude, dropoff_longitude = dropoff_longitude, requests_gender = request_gender,\\\n",
    "                                requests_race = request_race, arrival_rate = rider_arrival_rate, distance = None, utility = None))\n",
    "        r_id +=1\n",
    "\n",
    "    set_unique_ids(drivers)\n",
    "    set_unique_ids(requests)\n",
    "    for r in requests:\n",
    "        r.set_individual_rider_tolerance(random.choice(rider_tolerances)) #uniformly sample rider patience between {1, 2}\n",
    "\n",
    "\n",
    "    #2. Set the probability matrix\n",
    "    probability_matrix = np.empty([num_U,num_V])\n",
    "    for row in range(num_U):\n",
    "        for col in range(num_V):\n",
    "            driver_race = drivers[row].race\n",
    "            request_race = requests[col].race\n",
    "            if driver_race == 'white' and request_race == 'white':\n",
    "                probability_matrix[row,col] = 0.6\n",
    "            elif driver_race == 'white' and request_race == 'black':\n",
    "                probability_matrix[row,col] = 0.1\n",
    "            elif driver_race == 'black' and request_race == 'white':\n",
    "                probability_matrix[row,col] = 0.1\n",
    "            else:\n",
    "                probability_matrix[row,col] = 0.3\n",
    "\n",
    "    #3. Construct utility matrix\n",
    "    driver_pos = np.empty([num_U,2])\n",
    "    rider_pos = np.empty([num_V,2])\n",
    "    target_pos = np.empty([num_V,2])\n",
    "\n",
    "    for driver_idx in range(num_U):\n",
    "        driver_pos[driver_idx,0] = drivers[driver_idx].init_latitude\n",
    "        driver_pos[driver_idx,1] = drivers[driver_idx].init_longitude\n",
    "\n",
    "    for rider_idx in range(num_V):\n",
    "        rider_pos[rider_idx,0] = requests[rider_idx].start_latitude\n",
    "        rider_pos[rider_idx,1] = requests[rider_idx].start_longitude\n",
    "\n",
    "        target_pos[rider_idx,0] = requests[rider_idx].end_latitude\n",
    "        target_pos[rider_idx,1] = requests[rider_idx].end_longitude\n",
    "\n",
    "    driver_rider_dis = manhattan_distances(driver_pos,rider_pos)\n",
    "    trip_length = np.sum(np.abs(target_pos - rider_pos),axis = -1)\n",
    "    trip_length = np.tile(trip_length,(num_U,1))\n",
    "\n",
    "        #3.1Set the utility from three sides\n",
    "    driver_utility = trip_length - driver_rider_dis\n",
    "    driver_utility_matching = np.ones([num_U,num_V])\n",
    "    rider_utility = -driver_rider_dis# + np.max(driver_rider_dis)\n",
    "    rider_utility_matching = np.ones([num_U,num_V])\n",
    "    operator_utility = trip_length\n",
    "\n",
    "\n",
    "        #3.2scale them by a constant to be greater than 0\n",
    "    driver_utility -= np.min(driver_utility)\n",
    "    rider_utility -= np.min(rider_utility)\n",
    "\n",
    "    if verbose:\n",
    "        #print statistics of the utility matrix\n",
    "        t = PrettyTable(['','mean', 'std', 'min', 'max'])\n",
    "        t.title = 'utility statistics'\n",
    "        t.add_row(['operator utility'] + [operator_utility.mean(),operator_utility.std(),operator_utility.min(),operator_utility.max() ])\n",
    "        t.add_row(['driver utility'] + [driver_utility.mean(),driver_utility.std(),driver_utility.min(),driver_utility.max() ])\n",
    "        t.add_row(['driver utility matching'] + [driver_utility_matching.mean(),driver_utility_matching.std(),driver_utility_matching.min(),driver_utility_matching.max() ])\n",
    "        t.add_row(['rider utility'] + [rider_utility.mean(),rider_utility.std(),rider_utility.min(),rider_utility.max() ])\n",
    "        t.add_row(['rider utility matching'] + [rider_utility_matching.mean(),rider_utility_matching.std(),rider_utility_matching.min(),rider_utility_matching.max() ])\n",
    "        print(t)\n",
    "\n",
    "    #4. solve the LPs\n",
    "\n",
    "        #4.1 Operator LP TSGF\n",
    "    bound = np.reshape(np.array([0, 1]), (1, 2))\n",
    "    bounds_operator = np.tile(bound, (num_U * num_V, 1))\n",
    "    profit_c = get_operator_objective_kiid_sk(operator_utility * probability_matrix)\n",
    "    operator_A, operator_b = get_inequalities_operator_kiid_sk(drivers, requests, probability_matrix)\n",
    "    operator_x = linprog(profit_c, operator_A, operator_b, bounds=bounds_operator, method='highs')\n",
    "\n",
    "        #4.2 Driver LP TSGF\n",
    "    driver_c = get_driver_objective_kiid_sk(driver_utility)\n",
    "    driver_A, driver_b, driver_bounds = get_inequalities_driver_kiid_sk(drivers, requests, probability_matrix, driver_utility)\n",
    "    driver_x = linprog(driver_c, driver_A, driver_b, bounds=driver_bounds, method='highs')\n",
    "\n",
    "        #4.3 Rider LP TSGF\n",
    "    rider_c = get_rider_objective_kiid_sk(rider_utility)\n",
    "    rider_A, rider_b, rider_bounds = get_inequalities_rider_kiid_sk(drivers, requests, probability_matrix, rider_utility)\n",
    "    rider_x = linprog(rider_c, rider_A, rider_b, bounds=rider_bounds, method='highs')\n",
    "\n",
    "        #4.4 Driver LP Matching\n",
    "    driver_c_matching = get_driver_objective_kiid_sk(driver_utility_matching)\n",
    "    driver_A_matching, driver_b_matching, driver_bounds_matching = get_inequalities_driver_kiid_sk(drivers, requests,probability_matrix, driver_utility_matching)\n",
    "    driver_x_matching = linprog(driver_c_matching, driver_A_matching, driver_b_matching, bounds=driver_bounds_matching,method='highs')\n",
    "\n",
    "        #4.5 Rider LP Matching\n",
    "    rider_c_matching = get_rider_objective_kiid_sk(rider_utility_matching)\n",
    "    rider_A_matching, rider_b_matching, rider_bounds_matching = get_inequalities_rider_kiid_sk(drivers, requests,probability_matrix,rider_utility_matching)\n",
    "    rider_x_matching = linprog(rider_c_matching, rider_A_matching, rider_b_matching, bounds=rider_bounds_matching, method='highs')\n",
    "\n",
    "        #4.6 reshape the solutions\n",
    "    operator_x_2d = np.reshape(operator_x.x, [num_U, num_V])\n",
    "    driver_x_2d = np.reshape(driver_x.x[0:num_U * num_V], [num_U, num_V])\n",
    "    rider_x_2d = np.reshape(rider_x.x[0:num_U * num_V], [num_U, num_V])\n",
    "    driver_x_2d_matching = np.reshape(driver_x_matching.x[0:num_U * num_V], [num_U, num_V])\n",
    "    rider_x_2d_matching = np.reshape(rider_x_matching.x[0:num_U * num_V], [num_U, num_V])\n",
    "\n",
    "        #4.7 Calculate the statistics\n",
    "    operator_operator_ub = np.sum(np.sum(operator_x_2d * operator_utility * probability_matrix, axis=-1), axis=-1)\n",
    "    operator_driver_ub, operator_rider_ub = util_to_fairness(drivers, requests,\n",
    "                                                             np.sum(operator_x_2d * driver_utility * probability_matrix,\n",
    "                                                                    axis=1),\n",
    "                                                             np.sum(operator_x_2d * rider_utility * probability_matrix,\n",
    "                                                                    axis=0))\n",
    "\n",
    "    driver_operator_ub = np.sum(np.sum(driver_x_2d * operator_utility * probability_matrix, axis=-1), axis=-1)\n",
    "    driver_driver_ub, driver_rider_ub = util_to_fairness(drivers, requests,\n",
    "                                                         np.sum(driver_x_2d * driver_utility * probability_matrix, axis=1),\n",
    "                                                         np.sum(driver_x_2d * rider_utility * probability_matrix, axis=0))\n",
    "\n",
    "    rider_operator_ub = np.sum(np.sum(rider_x_2d * operator_utility * probability_matrix, axis=-1), axis=-1)\n",
    "    rider_driver_ub, rider_rider_ub = util_to_fairness(drivers, requests,\n",
    "                                                       np.sum(rider_x_2d * driver_utility * probability_matrix, axis=1),\n",
    "                                                       np.sum(rider_x_2d * rider_utility * probability_matrix, axis=0))\n",
    "\n",
    "    driver_operator_ub_matching = np.sum(np.sum(driver_x_2d_matching * operator_utility * probability_matrix, axis=-1),\n",
    "                                         axis=-1)\n",
    "    driver_driver_ub_matching, driver_rider_ub_matching = util_to_fairness(drivers, requests, np.sum(\n",
    "        driver_x_2d_matching * driver_utility * probability_matrix, axis=1), np.sum(\n",
    "        driver_x_2d_matching * rider_utility * probability_matrix, axis=0))\n",
    "\n",
    "    rider_operator_ub_matching = np.sum(np.sum(rider_x_2d_matching * operator_utility * probability_matrix, axis=-1),\n",
    "                                        axis=-1)\n",
    "    rider_driver_ub_matching, rider_rider_ub_matching = util_to_fairness(drivers, requests, np.sum(\n",
    "        rider_x_2d_matching * driver_utility * probability_matrix, axis=1), np.sum(\n",
    "        rider_x_2d_matching * rider_utility * probability_matrix, axis=0))\n",
    "\n",
    "    operator_ubs = [operator_operator_ub, operator_driver_ub, operator_rider_ub]\n",
    "    driver_ubs = [driver_operator_ub, driver_driver_ub, driver_rider_ub]\n",
    "    rider_ubs = [rider_operator_ub, rider_driver_ub, rider_rider_ub]\n",
    "    driver_ubs_matching = [driver_operator_ub_matching, driver_driver_ub_matching, driver_rider_ub_matching]\n",
    "    rider_ubs_matching = [rider_operator_ub_matching, rider_driver_ub_matching, rider_rider_ub_matching]\n",
    "\n",
    "    upper_bounds = np.array([operator_ubs[0], driver_ubs[1], rider_ubs[2]])\n",
    "    if verbose:\n",
    "        t = PrettyTable(['', 'profit', 'driver fairness', 'rider fairness'])\n",
    "        t.title = 'LP solutions'\n",
    "        t.add_row(['upper bounds'] + list(upper_bounds))\n",
    "        t.add_row(['operator LP'] + list(operator_ubs))\n",
    "        t.add_row(['driver LP'] + list(driver_ubs))\n",
    "        t.add_row(['driver matching LP'] + list(driver_ubs_matching))\n",
    "        t.add_row(['rider LP'] + list(rider_ubs))\n",
    "        t.add_row(['rider matching LP'] + list(rider_ubs_matching))\n",
    "        print(t)\n",
    "\n",
    "    #5. run the experiment\n",
    "    requests_copy = copy.deepcopy(requests)\n",
    "    results_TSGF_inner = []\n",
    "    results_matching_inner = []\n",
    "\n",
    "    for n in range(len(alphas)):\n",
    "        t0 = time.time()\n",
    "        alpha = alphas[n]\n",
    "        beta = betas[n]\n",
    "        gamma = gammas[n]\n",
    "\n",
    "        match_results = np.zeros([num_loops,num_U,num_V])\n",
    "        for i in range(num_loops):\n",
    "            drivers_copy = [copy.deepcopy(d) for d in drivers]\n",
    "            run_TSGF_express(i,match_results,requests_copy, drivers_copy, probability_matrix, operator_x_2d,driver_x_2d, rider_x_2d,alpha=alpha, beta = beta, gamma = gamma)\n",
    "\n",
    "        driver_mean_utility = np.mean(np.sum(match_results * driver_utility,axis = -1),axis = 0)\n",
    "        rider_mean_utility = np.mean(np.sum(match_results * rider_utility,axis = -2),axis = 0)\n",
    "        operator_mean_utility = np.mean(np.sum(np.sum(match_results * operator_utility,axis = -1),axis = -1),axis = 0)\n",
    "\n",
    "        expost_d_fairness, expost_r_fairness = util_to_fairness(drivers,requests,driver_mean_utility,rider_mean_utility)\n",
    "        results_TSGF_inner.append([operator_mean_utility, expost_d_fairness,expost_r_fairness])\n",
    "\n",
    "        #FOR Matching\n",
    "\n",
    "        match_results = np.zeros([num_loops,num_U,num_V])\n",
    "        for i in range(num_loops):\n",
    "            drivers_copy = [copy.deepcopy(d) for d in drivers]\n",
    "            run_TSGF_express(i,match_results,requests_copy, drivers_copy, probability_matrix, operator_x_2d,driver_x_2d_matching, rider_x_2d_matching,alpha=alpha, beta = beta, gamma = gamma)\n",
    "\n",
    "        driver_mean_utility = np.mean(np.sum(match_results * driver_utility,axis = -1),axis = 0)\n",
    "        rider_mean_utility = np.mean(np.sum(match_results * rider_utility,axis = -2),axis = 0)\n",
    "        operator_mean_utility = np.mean(np.sum(np.sum(match_results * operator_utility,axis = -1),axis = -1),axis = 0)\n",
    "\n",
    "        expost_d_fairness, expost_r_fairness = util_to_fairness(drivers,requests,driver_mean_utility,rider_mean_utility)\n",
    "        results_matching_inner.append([operator_mean_utility, expost_d_fairness,expost_r_fairness])\n",
    "        if verbose:\n",
    "            print(alpha, beta, gamma, time.time() - t0)\n",
    "\n",
    "\n",
    "    results = np.array(results_TSGF_inner)\n",
    "    results_matching = np.array(results_matching_inner)\n",
    "\n",
    "    profit_crs = np.reshape(results[:,0] / upper_bounds[0],[alphas.shape[0],1])\n",
    "    driver_fairness_crs = np.reshape(results[:,1] / upper_bounds[1],[alphas.shape[0],1])\n",
    "    rider_fairness_crs = np.reshape(results[:,2] / upper_bounds[2],[alphas.shape[0],1])\n",
    "\n",
    "    profit_crs_matching = np.reshape(results_matching[:,0] / upper_bounds[0],[alphas.shape[0],1])\n",
    "    driver_fairness_crs_matching = np.reshape(results_matching[:,1] / upper_bounds[1],[alphas.shape[0],1])\n",
    "    rider_fairness_crs_matching = np.reshape(results_matching[:,2] / upper_bounds[2],[alphas.shape[0],1])\n",
    "\n",
    "    TSGF_crs = np.hstack([profit_crs, driver_fairness_crs, rider_fairness_crs])\n",
    "    matching_crs = np.hstack([profit_crs_matching, driver_fairness_crs_matching, rider_fairness_crs_matching])\n",
    "\n",
    "\n",
    "    return TSGF_crs, matching_crs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "start_t = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "num_trials = 100\n",
    "num_loops = 100\n",
    "num_ticks = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_U = 49\n",
    "num_V = 172\n",
    "\n",
    "driver_quotas = [3] #driver patience set to 3\n",
    "rider_tolerances = [1,2]\n",
    "driver_capacity = 1\n",
    "rider_arrival_rate = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "alphas = np.array([0.5,0.5])\n",
    "betas = np.array([0,0.5])\n",
    "gammas = np.array([0.5,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10814\n",
      "35109\n",
      "1\n",
      "10814\n",
      "35109\n",
      "2\n",
      "10814\n",
      "35109\n",
      "3\n",
      "10814\n",
      "35109\n",
      "4\n",
      "10814\n",
      "35109\n",
      "5\n",
      "10814\n",
      "35109\n",
      "6\n",
      "10814\n",
      "35109\n",
      "7\n",
      "10814\n",
      "35109\n",
      "8\n",
      "10814\n",
      "35109\n",
      "9\n",
      "10814\n",
      "35109\n",
      "10\n",
      "10814\n",
      "35109\n",
      "11\n",
      "10814\n",
      "35109\n",
      "12\n",
      "10814\n",
      "35109\n",
      "13\n",
      "10814\n",
      "35109\n",
      "14\n",
      "10814\n",
      "35109\n",
      "15\n",
      "10814\n",
      "35109\n",
      "16\n",
      "10814\n",
      "35109\n",
      "17\n",
      "10814\n",
      "35109\n",
      "18\n",
      "10814\n",
      "35109\n",
      "19\n",
      "10814\n",
      "35109\n",
      "20\n",
      "10814\n",
      "35109\n",
      "21\n",
      "10814\n",
      "35109\n",
      "22\n",
      "10814\n",
      "35109\n",
      "23\n",
      "10814\n",
      "35109\n",
      "24\n",
      "10814\n",
      "35109\n",
      "25\n",
      "10814\n",
      "35109\n",
      "26\n",
      "10814\n",
      "35109\n",
      "27\n",
      "10814\n",
      "35109\n",
      "28\n",
      "10814\n",
      "35109\n",
      "29\n",
      "10814\n",
      "35109\n",
      "30\n",
      "10814\n",
      "35109\n",
      "31\n",
      "10814\n",
      "35109\n",
      "32\n",
      "10814\n",
      "35109\n",
      "33\n",
      "10814\n",
      "35109\n",
      "34\n",
      "10814\n",
      "35109\n",
      "35\n",
      "10814\n",
      "35109\n",
      "36\n",
      "10814\n",
      "35109\n",
      "37\n",
      "10814\n",
      "35109\n",
      "38\n",
      "10814\n",
      "35109\n",
      "39\n",
      "10814\n",
      "35109\n",
      "40\n",
      "10814\n",
      "35109\n",
      "41\n",
      "10814\n",
      "35109\n",
      "42\n",
      "10814\n",
      "35109\n",
      "43\n",
      "10814\n",
      "35109\n",
      "44\n",
      "10814\n",
      "35109\n",
      "45\n",
      "10814\n",
      "35109\n",
      "46\n",
      "10814\n",
      "35109\n",
      "47\n",
      "10814\n",
      "35109\n",
      "48\n",
      "10814\n",
      "35109\n",
      "49\n",
      "10814\n",
      "35109\n",
      "50\n",
      "10814\n",
      "35109\n",
      "51\n",
      "10814\n",
      "35109\n",
      "52\n",
      "10814\n",
      "35109\n",
      "53\n",
      "10814\n",
      "35109\n",
      "54\n",
      "10814\n",
      "35109\n",
      "55\n",
      "10814\n",
      "35109\n",
      "56\n",
      "10814\n",
      "35109\n",
      "57\n",
      "10814\n",
      "35109\n",
      "58\n",
      "10814\n",
      "35109\n",
      "59\n",
      "10814\n",
      "35109\n",
      "60\n",
      "10814\n",
      "35109\n",
      "61\n",
      "10814\n",
      "35109\n",
      "62\n",
      "10814\n",
      "35109\n",
      "63\n",
      "10814\n",
      "35109\n",
      "64\n",
      "10814\n",
      "35109\n",
      "65\n",
      "10814\n",
      "35109\n",
      "66\n",
      "10814\n",
      "35109\n",
      "67\n",
      "10814\n",
      "35109\n",
      "68\n",
      "10814\n",
      "35109\n",
      "69\n",
      "10814\n",
      "35109\n",
      "70\n",
      "10814\n",
      "35109\n",
      "71\n",
      "10814\n",
      "35109\n",
      "72\n",
      "10814\n",
      "35109\n",
      "73\n",
      "10814\n",
      "35109\n",
      "74\n",
      "10814\n",
      "35109\n",
      "75\n",
      "10814\n",
      "35109\n",
      "76\n",
      "10814\n",
      "35109\n",
      "77\n",
      "10814\n",
      "35109\n",
      "78\n",
      "10814\n",
      "35109\n",
      "79\n",
      "10814\n",
      "35109\n",
      "80\n",
      "10814\n",
      "35109\n",
      "81\n",
      "10814\n",
      "35109\n",
      "82\n",
      "10814\n",
      "35109\n",
      "83\n",
      "10814\n",
      "35109\n",
      "84\n",
      "10814\n",
      "35109\n",
      "85\n",
      "10814\n",
      "35109\n",
      "86\n",
      "10814\n",
      "35109\n",
      "87\n",
      "10814\n",
      "35109\n",
      "88\n",
      "10814\n",
      "35109\n",
      "89\n",
      "10814\n",
      "35109\n",
      "90\n",
      "10814\n",
      "35109\n",
      "91\n",
      "10814\n",
      "35109\n",
      "92\n",
      "10814\n",
      "35109\n",
      "93\n",
      "10814\n",
      "35109\n",
      "94\n",
      "10814\n",
      "35109\n",
      "95\n",
      "10814\n",
      "35109\n",
      "96\n",
      "10814\n",
      "35109\n",
      "97\n",
      "10814\n",
      "35109\n",
      "98\n",
      "10814\n",
      "35109\n",
      "99\n",
      "10814\n",
      "35109\n",
      "1954.2032566070557\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "results_TSGF, results_matching = np.zeros([num_trials, num_ticks,3]), np.zeros([num_trials, num_ticks,3])\n",
    "for i in range(num_trials):\n",
    "    print(i)\n",
    "    results_TSGF_single, results_matching_single = run_experiment(num_U,num_V,driver_quotas,rider_tolerances, alphas, betas, gammas, num_loops)\n",
    "    results_TSGF[i,:,:] =  results_TSGF_single\n",
    "    results_matching[i,:,:] =  results_matching_single\n",
    "print(time.time() - t0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "results_TSGF_mean = np.mean(results_TSGF,axis = 0)\n",
    "results_matching_mean = np.mean(results_matching,axis = 0)\n",
    "results_TSGF_bar = np.std(results_TSGF,axis = 0)\n",
    "results_matching_bar = np.std(results_matching,axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43047054 0.38685153 0.50914857]\n",
      " [0.56405753 0.49785806 0.40969978]]\n"
     ]
    }
   ],
   "source": [
    "print(results_TSGF_mean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41644927 0.36141623 0.46233399]\n",
      " [0.45151097 0.44025602 0.36140453]]\n"
     ]
    }
   ],
   "source": [
    "print(results_matching_mean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}